{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SE61uTCxnLe",
        "outputId": "3f5e1a42-3411-4459-e731-4747cd7d1b0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 20, 20, 1)\n",
            "(10000, 20, 20, 1)\n",
            "(60000, 400)\n",
            "(10000, 400)\n",
            "Test Accuracy: 0.902\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Define the Perceptron class with vectorized operations\n",
        "class Perceptron:\n",
        "    def __init__(self, input_size, learning_rate=0.01):  # Corrected __init__ method\n",
        "        self.weights = np.random.randn(input_size, 1) * 0.01\n",
        "        self.bias = 0.01\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = np.dot(x, self.weights) + self.bias\n",
        "        return self.sigmoid(z)\n",
        "\n",
        "    def train(self, x, y, epochs=100, learning_rate=0.001):\n",
        "        y = y.reshape(-1, 1)  # Ensure y is correctly shaped for training\n",
        "        for epoch in range(epochs):\n",
        "            output = self.forward(x)\n",
        "            error = y - output\n",
        "            self.weights += learning_rate * np.dot(x.T, error * output * (1 - output))\n",
        "            self.bias += learning_rate * np.sum(error * output * (1 - output))\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.forward(x)\n",
        "\n",
        "\n",
        "def load_and_preprocess_data():\n",
        "    # Load the MNIST dataset\n",
        "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "    train_images_with_channel = tf.expand_dims(train_images, -1)\n",
        "    test_images_with_channel = tf.expand_dims(test_images, -1)\n",
        "\n",
        "    # Resize images to 20x20 and normalize\n",
        "    train_images_resized = tf.image.resize(train_images_with_channel, [20, 20]).numpy() / 255.0\n",
        "    test_images_resized = tf.image.resize(test_images_with_channel, [20, 20]).numpy() / 255.0\n",
        "    print(train_images_resized.shape)\n",
        "    print(test_images_resized.shape)\n",
        "    # Reshape images to flatten them into vectors of size 400 (20*20)\n",
        "    x_train = train_images_resized.reshape(-1, 20*20)  # Reshape to (-1, 400)\n",
        "    x_test = test_images_resized.reshape(-1, 20*20)    # Reshape to (-1, 400)\n",
        "    print(x_train.shape)\n",
        "    print(x_test.shape)\n",
        "\n",
        "    return x_train, train_labels, x_test, test_labels\n",
        "\n",
        "x_train, train_labels, x_test, test_labels = load_and_preprocess_data()\n",
        "\n",
        "# Convert labels to binary: '0' vs. others\n",
        "y_train_binary = (train_labels == 0).astype(int)\n",
        "y_test_binary = (test_labels == 0).astype(int)\n",
        "\n",
        "# Initialize and train the Perceptron\n",
        "perceptron = Perceptron(400, learning_rate=0.001)  # Adjusted learning rate\n",
        "perceptron.train(x_train, y_train_binary, epochs=100)  # Adjusted number of epochs\n",
        "\n",
        "# Test the model and calculate accuracy\n",
        "raw_predictions = perceptron.predict(x_test)\n",
        "y_test_pred = (raw_predictions > 0.5).astype(int)  # Vectorized thresholding\n",
        "\n",
        "# Calculate and print test accuracy\n",
        "accuracy = np.mean(y_test_pred.flatten() == y_test_binary)\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EGs4-9yIg4oP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}