{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tvs-AYQTmXiJ",
        "outputId": "543c1b59-be0f-4ad6-897f-9f95dba6e33e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Images created and saved successfully.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def create_handwritten_digit_images(digit, variations=10, size=(20, 20)):\n",
        "    images = []\n",
        "    for i in range(variations):\n",
        "        img = Image.new('L', size, color=255) # 'L' mode for grayscale\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        text_xy = (size[0] // 4, size[1] // 4) # Position text roughly in the center\n",
        "        draw.text(text_xy, str(digit), fill=0) # 0 for black text\n",
        "        images.append(img)\n",
        "    return images\n",
        "\n",
        "# Directory to save images\n",
        "os.makedirs('/mnt/data/handwritten_digits', exist_ok=True)\n",
        "\n",
        "# Generate images for each digit\n",
        "for digit in range(10):\n",
        "    digit_images = create_handwritten_digit_images(digit)\n",
        "    for i, img in enumerate(digit_images):\n",
        "        img.save(f'/mnt/data/handwritten_digits/{digit}_{i}.png')\n",
        "\n",
        "\"Images created and saved successfully.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Activation Function: Sigmoid\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Derivative of Sigmoid (used in backpropagation)\n",
        "def sigmoid_derivative(x):\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "# Loss Function: Mean Squared Error\n",
        "def mean_squared_error(y_true, y_pred):\n",
        "    return ((y_true - y_pred) ** 2).mean()\n",
        "\n",
        "# Perceptron Class\n",
        "class Perceptron:\n",
        "    def __init__(self, input_size, learning_rate=0.01, activation_function=sigmoid, loss_function=mean_squared_error):\n",
        "        self.weights = np.random.rand(input_size + 1) # +1 for bias\n",
        "        self.learning_rate = learning_rate\n",
        "        self.activation_function = activation_function\n",
        "        self.loss_function = loss_function\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        summation = np.dot(inputs, self.weights[1:]) + self.weights[0] # Weights and Bias\n",
        "        return self.activation_function(summation)\n",
        "\n",
        "    def train(self, training_inputs, labels, epochs=1000):\n",
        "        for epoch in range(epochs):\n",
        "            for inputs, label in zip(training_inputs, labels):\n",
        "                prediction = self.predict(inputs)\n",
        "                error = label - prediction\n",
        "                adjustments = self.learning_rate * error * sigmoid_derivative(prediction)\n",
        "                self.weights[1:] += adjustments * inputs\n",
        "                self.weights[0] += adjustments\n",
        "\n",
        "    def evaluate(self, test_inputs, test_labels):\n",
        "        predictions = np.array([self.predict(inputs) for inputs in test_inputs])\n",
        "        loss = self.loss_function(test_labels, predictions)\n",
        "        return loss\n",
        "\n",
        "# Placeholder for loading and preprocessing the images\n",
        "def load_and_preprocess_images(image_paths):\n",
        "    # Dummy function, to be implemented\n",
        "    pass\n",
        "\n",
        "# Note: The next steps will involve loading the images, preprocessing them into a suitable format for training, and then using the Perceptron class for training and testing.\n",
        "\n",
        "\"Perceptron software components developed.\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "djfZF87QmYki",
        "outputId": "1fe9c117-92e1-41b9-90e2-34f4aff909b6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Perceptron software components developed.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "def load_and_preprocess_images(image_folder):\n",
        "    image_data = []\n",
        "    labels = []\n",
        "\n",
        "    # Load each image and its label\n",
        "    for digit in range(10):\n",
        "        for image_file in glob.glob(f'{image_folder}/{digit}_*.png'):\n",
        "            img = Image.open(image_file)\n",
        "            img_data = np.array(img).flatten() / 255.0  # Normalize pixel values\n",
        "            image_data.append(img_data)\n",
        "            labels.append(digit)\n",
        "\n",
        "    return np.array(image_data), np.array(labels)\n",
        "\n",
        "# Load and preprocess the training images\n",
        "image_folder = '/mnt/data/handwritten_digits'\n",
        "training_images, training_labels = load_and_preprocess_images(image_folder)\n",
        "\n",
        "# Create the Perceptron\n",
        "input_size = training_images.shape[1]  # Number of pixels in each image\n",
        "perceptron = Perceptron(input_size)\n",
        "\n",
        "# Placeholder for creating test images\n",
        "# Note: In a real scenario, you should have a separate set of images for testing. Here, we are using the same images for simplicity.\n",
        "\n",
        "# Train the Perceptron\n",
        "epochs = 1000  # Number of times to iterate over the training data\n",
        "perceptron.train(training_images, training_labels, epochs)\n",
        "\n",
        "# Evaluate the Perceptron (using training data as a placeholder for test data)\n",
        "loss = perceptron.evaluate(training_images, training_labels)\n",
        "\n",
        "\"Perceptron trained. Loss on training data (used as a placeholder for test data):\", loss\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qj3V2nLLmYgk",
        "outputId": "5accda77-d4d1-4da2-d7c9-cb7e874af43b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Perceptron trained. Loss on training data (used as a placeholder for test data):',\n",
              " 20.5)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "# Load MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Resize images to 20x20\n",
        "train_images_resized = tf.image.resize(train_images, [20, 20]).numpy()\n",
        "test_images_resized = tf.image.resize(test_images, [20, 20]).numpy()\n",
        "\n",
        "# Normalize pixel values\n",
        "train_images_resized = train_images_resized / 255.0\n",
        "test_images_resized = test_images_resized / 255.0\n",
        "\n",
        "# Perceptron class definition\n",
        "class Perceptron:\n",
        "    def __init__(self, input_size, learning_rate=0.01):\n",
        "        self.weights = np.random.randn(input_size, 1)\n",
        "        self.bias = np.random.randn(1)\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def loss(self, y_true, y_pred):\n",
        "        return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = np.dot(x, self.weights) + self.bias\n",
        "        return self.sigmoid(z)\n",
        "\n",
        "    def backpropagation(self, x, y_true, y_pred):\n",
        "        dw = (1 / len(x)) * np.dot(x.T, (y_pred - y_true))\n",
        "        db = np.mean(y_pred - y_true)\n",
        "        self.weights -= self.learning_rate * dw\n",
        "        self.bias -= self.learning_rate * db\n",
        "\n",
        "    def train(self, x, y, epochs):\n",
        "        for epoch in range(epochs):\n",
        "            for i in range(len(x)):\n",
        "                y_pred = self.forward(x[i:i+1])\n",
        "                self.backpropagation(x[i:i+1], y[i:i+1], y_pred)\n",
        "            if epoch % 10 == 0:\n",
        "                loss = self.loss(y, self.forward(x))\n",
        "                print(f'Epoch {epoch}, Loss: {loss}')\n",
        "\n",
        "# Flattening images and preparing labels for binary classification\n",
        "x_train = train_images_resized.reshape(-1, 400)\n",
        "y_train = np.where(train_labels == 0, 1, 0)\n",
        "\n",
        "# Create and train the Perceptron\n",
        "perceptron = Perceptron(input_size=400)\n",
        "perceptron.train(x_train, y_train, epochs=50)\n",
        "\n",
        "# Preprocess test data\n",
        "x_test = test_images_resized.reshape(-1, 400)\n",
        "y_test = np.where(test_labels == 0, 1, 0)\n",
        "\n",
        "# Test the model\n",
        "y_pred = perceptron.forward(x_test)\n",
        "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwYdHRarouVr",
        "outputId": "6d2828af-03ef-4e03-c357-bc5521554ddf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 1.0799692919665054\n",
            "Epoch 10, Loss: 0.6694071230100745\n",
            "Epoch 20, Loss: 0.6536464884103075\n",
            "Epoch 30, Loss: 0.6666494349982526\n",
            "Epoch 40, Loss: 0.6910293295445182\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8732857142857143"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}